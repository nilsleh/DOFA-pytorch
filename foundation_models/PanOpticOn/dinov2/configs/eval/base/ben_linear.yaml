
model:
  id: dinov2
  model_kwargs:
    arch: vit_base
    patch_size: 14
    embed_layer: ChnAttnPatchEmb
    add_pe_args:
      id_attn_block: ChnAttnBlockSimple
      norm_input: false
      use_layer_scale: false
      skip_conn: true
      norm_output: false

  autocast_dtype: fp16
  pretrained_weights:
  - path: /data/panopticon/logs/dino_logs/sattn/long_rchns/base_lr=1e-3_warmup=0/model_final.pth
    include: teacher.backbone.
    prefix_map:
      teacher.backbone.: ''


task:
  id: multilabelclassification

_vars: # not explicitly used in config, only as variables
  transform: # output is 120x120
  - id: ChnSelect
    idxs: [3,2,1]
  - id: Resize
    size: 112 # divisible by 14

train_dataset:
  id: geobench.m-bigearthnet
  subset: 10
  split: train
  transform: ${_vars.transform}

val_dataset:
  id: geobench.m-bigearthnet
  split: val
  subset: 50
  transform: ${_vars.transform}

test_datasets_list:
  - id: geobench.m-bigearthnet
    split: test
    subset: 50
    transform: ${_vars.transform}

dl:
  batch_size: 10
  num_workers: 4
  persistent_workers: true

optim:
  epochs: 2 # or max_iter

  save_checkpoint_frequency_epoch: 50
  eval_period_epoch: 1