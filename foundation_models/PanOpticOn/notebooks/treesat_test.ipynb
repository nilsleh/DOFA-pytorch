{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: /data/panopticon/datasets/treesat/train_filenames.lst\n"
     ]
    }
   ],
   "source": [
    "from dinov2.data.datasets.treesat import TreeSAT, TreeSATWrapper\n",
    "\n",
    "\n",
    "base_path = '/data/panopticon/datasets/treesat/'\n",
    "modalities = ['aerial', 's2-mono', 's1-mono']\n",
    "\n",
    "treesat = TreeSATWrapper(base_path, modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['treesat-s1', 'treesat-s2', 'treesat-aerial'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treesat.sensor_name_mapping.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s1-mono': tensor([-1, -2], dtype=torch.int32),\n",
       " 's2-mono': tensor([ 492,  559,  664,  832,  704,  740,  782,  864, 1613, 2202,  442,  945],\n",
       "        dtype=torch.int32),\n",
       " 'aerial': tensor([840, 650, 560, 450], dtype=torch.int32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treesat.chn_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['imgs', 'chn_ids'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(0, len(treesat)-1)\n",
    "sample, labels = treesat[i]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 304, 304]), torch.Size([2, 6, 6]), torch.Size([12, 6, 6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['imgs'][0][0].shape, sample['imgs'][1][0].shape, sample['imgs'][2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([840, 650, 560, 450], dtype=torch.int32),\n",
       "  tensor([-1, -2], dtype=torch.int32),\n",
       "  tensor([ 492,  559,  664,  832,  704,  740,  782,  864, 1613, 2202,  442,  945],\n",
       "         dtype=torch.int32)],\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['chn_ids'], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.8589),\n",
       " tensor(4.8971),\n",
       " tensor(-0.0220),\n",
       " tensor(0.1916),\n",
       " tensor(-1.1887),\n",
       " tensor(0.9105))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['imgs'][0][0].min(), sample['imgs'][0][0].max(), sample['imgs'][1][0].min(), sample['imgs'][1][0].max(), sample['imgs'][2][0].min(), sample['imgs'][2][0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess TreeSAT AI data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original filename :  Abies_alba_1_1005_WEFL_NLF.tif\n",
      "filename :  /data/panopticon/datasets/treesat/sentinel-ts/Abies_alba_1_1005_WEFL_NLF.h5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/data/panopticon/datasets/treesat/sentinel/Abies_alba_1_1005_WEFL_NLF.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal filename : \u001b[39m\u001b[38;5;124m\"\u001b[39m,file_name)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename : \u001b[39m\u001b[38;5;124m\"\u001b[39m, data_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentinel-ts/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentinel/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     37\u001b[0m     s1_asc \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msen-1-asc-data\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]\n\u001b[1;32m     38\u001b[0m     s1_asc \u001b[38;5;241m=\u001b[39m replace_nans_with_mean(torch\u001b[38;5;241m.\u001b[39mtensor(s1_asc))\n",
      "File \u001b[0;32m~/.conda/envs/dinov2/lib/python3.10/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.conda/envs/dinov2/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/data/panopticon/datasets/treesat/sentinel/Abies_alba_1_1005_WEFL_NLF.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def replace_nans_with_mean(batch_of_images):\n",
    "    # Calculate the mean along the specified axis (axis=(2, 3) for temp, channels, height, width)\n",
    "    image_means = torch.nanmean(batch_of_images, dim=(2, 3), keepdim=True)\n",
    "\n",
    "    # Create a mask for NaN values\n",
    "    nan_mask = torch.isnan(batch_of_images)\n",
    "\n",
    "    # Use PyTorch broadcasting to replace NaN values with corresponding means\n",
    "    batch_of_images[nan_mask] = image_means.expand_as(batch_of_images)[nan_mask]\n",
    "\n",
    "    nan_mask = torch.isnan(image_means).any(dim=1).squeeze()\n",
    "\n",
    "    # Filter out the time steps where there are NaN values\n",
    "    batch_of_images = batch_of_images[~nan_mask]\n",
    "\n",
    "    return batch_of_images\n",
    "\n",
    "data_dir = \"/data/panopticon/datasets/treesat/\" #path of data\n",
    "\n",
    "with open(data_dir + \"train_filenames.lst\", 'r') as file:\n",
    "    lst_list = [line.strip() for line in file.readlines()]\n",
    "\n",
    "with open(data_dir + \"val_filenames.lst\", 'r') as file:\n",
    "    lst_list += [line.strip() for line in file.readlines()]\n",
    "\n",
    "with open(data_dir + \"test_filenames.lst\", 'r') as file:\n",
    "    lst_list += [line.strip() for line in file.readlines()]\n",
    "\n",
    "for file_name in lst_list:\n",
    "    print(\"original filename : \",file_name)\n",
    "    print(\"filename : \", data_dir + \"sentinel-ts/\" + '.'.join(file_name.split('.')[:-1]) + \".h5\")\n",
    "    with h5py.File(data_dir + \"sentinel/\" + '.'.join(file_name.split('.')[:-1]) + \".h5\", 'r') as file:\n",
    "        s1_asc = file[\"sen-1-asc-data\"][:]\n",
    "        s1_asc = replace_nans_with_mean(torch.tensor(s1_asc))\n",
    "        file_path = data_dir + \"s1-asc/\" + '.'.join(file_name.split('.')[:-1]) + \".pth\"\n",
    "        s1_asc = torch.cat([s1_asc, (s1_asc[:, 0, :, :]/(s1_asc[:, 1, :, :] + 1e-8)).unsqueeze(1)], dim = 1)\n",
    "        if torch.isnan(s1_asc).any().item():\n",
    "            print(file_name)\n",
    "        torch.save(s1_asc, file_path)\n",
    "        s1_des = file[\"sen-1-des-data\"][:]\n",
    "        s1_des = replace_nans_with_mean(torch.tensor(s1_des))\n",
    "        s1_des = torch.cat([s1_des, (s1_des[:, 0, :, :]/(s1_des[:, 1, :, :] + 1e-8)).unsqueeze(1)], dim = 1)\n",
    "        if torch.isnan(s1_des).any().item():\n",
    "            print(\"s1-des\", file_name)\n",
    "        file_path = data_dir + \"s1-des/\" + '.'.join(file_name.split('.')[:-1]) + \".pth\"\n",
    "        torch.save(s1_des, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
